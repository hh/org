#+TITLE: apisnoop/ci for per branch instances
#+AUTHOR: Hippie Hacker
#+EMAIL: hh@ii.coop
#+CREATOR: ii.coop
#+DATE: 8th of March, 2019
#+PROPERTY: header-args:shell :results output code verbatim replace
#+PROPERTY: header-args:shell+ :exports both
#+PROPERTY: header-args:shell+ :wrap "EXAMPLE :noeval t"
#+NOPROPERTY: header-args:tmate  :socket (symbol-value 'socket)
#+PROPERTY: header-args:tmate+ :session (concat (user-login-name) ":" (nth 4 (org-heading-components)))
#+PROPERTY: header-args:shell+ :eval no-export
#+PROPERTY: header-args:tmate+ :eval no-export
#+REVEAL_ROOT: http://cdn.jsdelivr.net/reveal.js/3.0.0/
#+STARTUP: content
[[file:~/test-infra/prow/plugins/config.go::type%20ProjectConfig%20struct%20{]]
* Overview

Our software developers needed to work on multiple issues / branches at the same
time. We needed to be able to compare different data generation methods and
visualizations. We have explored a few options (static sites via netflify, and various CI providers),
but feel our workflow with GitLab worth sharing.

** Mirror => Pipelines => Jobs => Environments

We mirror from our repo to a CI-only Gitlab project.

Each commit on a branch triggers a pipeline, and a set of jobs:

- [[https://gitlab.ii.coop/apisnoop/ci/branches][branches]] => [[https://gitlab.ii.coop/apisnoop/ci/pipelines][pipelines]] => [[https://gitlab.ii.coop/apisnoop/ci/-/jobs][jobs]]

The deploy jobs create environments per branch:

- [[https://gitlab.ii.coop/apisnoop/ci/environments][environments]] => [[https://gitlab.ii.coop/apisnoop/ci/environments/folders/review][review/*branch*]]

Mirror settings:

- [[https://gitlab.ii.coop/apisnoop/ci/settings/repository][settings/repository/mirroring]]

** Example  

Example commit pipeline to deploy

- [[https://gitlab.ii.coop/apisnoop/ci/commit/eccfa3ce17d457754ee1d544910aeea22d2af600][UAFilter-commit]] 
- [[https://gitlab.ii.coop/apisnoop/ci/pipelines/281][pipeline#281]] 
- [[https://gitlab.ii.coop/apisnoop/ci/-/jobs/1871][build]] and [[https://gitlab.ii.coop/apisnoop/ci/-/jobs/1872][deploy]]  jobs
- [[https://gitlab.ii.coop/apisnoop/ci/environments/42][environment]]
- [[https://gitlab.ii.coop/apisnoop/ci/environments/42/terminal][console]]
- [[https://apisnoop-ci-review-tix-121-ltf42v.apisnoop.cncf.ci/][apisnoop-ci-review-BRANCHNAME.apisnoop.cncf.ci]]

** Basics of using review/BRANCH deployment

We also have a Prow bot (@cncf-ci) watching our upstream repo on Github.
When a new pull request is created, the bot will respond with pipeline results.

Flow is as follows: 

- [X] Create a PR
- [X] Wait for @cncf-ci to respond with your pipeline results
- [X] Inspect Pipeline logs and visit deployment url

* Kubernetes Cluster Overview
  
[[https://gitlab.ii.coop/apisnoop/ci/clusters/23]]

** namespaces

Jobs running in the ~gitlab-managed-apps~ namespace created/manage the
~apisnoop-ci~ namespace.
   
#+NAME: namespaces
#+BEGIN_SRC shell
  kubectl get namespaces
#+END_SRC

#+RESULTS: namespaces
#+BEGIN_EXAMPLE :noeval t
NAME                  STATUS   AGE
apisnoop-ci           Active   1d
default               Active   11d
gitlab-managed-apps   Active   11d
kube-public           Active   11d
kube-system           Active   11d
openfisca-aotearoa    Active   7d
raputure              Active   7d
#+END_EXAMPLE

** gitlab-managed-apps namespace

The job runners and CI infrastructure not specific to our project run in the
~gitlab-managed-apps~ namespace.

#+NAME: runner / certmgr / ingress / prometheus pods
#+BEGIN_SRC shell
  kubectl --namespace=gitlab-managed-apps get pods | grep -v rror
#+END_SRC

#+RESULTS: runner / certmgr / ingress / prometheus pods
#+BEGIN_EXAMPLE :noeval t
NAME                                                     READY   STATUS    RESTARTS   AGE
certmanager-cert-manager-6c8cd9f9bf-kjjsq                1/1     Running   3          11d
ingress-nginx-ingress-controller-ff666c548-vgcjr         1/1     Running   0          11d
ingress-nginx-ingress-default-backend-6679dd498c-nqh7p   1/1     Running   0          11d
prometheus-kube-state-metrics-8668948654-6qj5m           1/1     Running   0          11d
prometheus-prometheus-server-746bb67956-dzxz9            2/2     Running   0          11d
runner-gitlab-runner-9df899f44-smgtx                     1/1     Running   0          11d
tiller-deploy-9768f6964-qtb9m                            1/1     Running   0          11d
#+END_EXAMPLE
*** everything
#+NAME: helm
#+BEGIN_SRC shell
(
  helm list --namespace=gitlab-managed-apps
) 2>&1
:
#+END_SRC

#+RESULTS: helm
#+BEGIN_EXAMPLE :noeval t
Error: configmaps is forbidden: User "system:serviceaccount:kube-system:default" cannot list configmaps in the namespace "kube-system"
#+END_EXAMPLE

#+NAME: all gitlab-managed-app namespace k8s objects
#+BEGIN_SRC shell
  kubectl --namespace=gitlab-managed-apps get all #| grep -v Error
#+END_SRC

#+RESULTS: all gitlab-managed-app namespace k8s objects
#+BEGIN_EXAMPLE :noeval t
NAME                                                         READY   STATUS    RESTARTS   AGE
pod/certmanager-cert-manager-6c8cd9f9bf-kjjsq                1/1     Running   3          12d
pod/ingress-nginx-ingress-controller-ff666c548-vgcjr         1/1     Running   0          12d
pod/ingress-nginx-ingress-default-backend-6679dd498c-nqh7p   1/1     Running   0          12d
pod/install-certmanager                                      0/1     Error     0          2d
pod/install-ingress                                          0/1     Error     0          2d
pod/install-prometheus                                       0/1     Error     0          2d
pod/install-runner                                           0/1     Error     0          2d
pod/prometheus-kube-state-metrics-8668948654-6qj5m           1/1     Running   0          12d
pod/prometheus-prometheus-server-746bb67956-dzxz9            2/2     Running   0          12d
pod/runner-gitlab-runner-9df899f44-smgtx                     1/1     Running   0          12d
pod/runner-zf8zf8jb-project-142-concurrent-0rcwf6            3/3     Running   0          31s
pod/tiller-deploy-9768f6964-qtb9m                            1/1     Running   0          12d
NAME                                             TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)                      AGE
service/ingress-nginx-ingress-controller         LoadBalancer   10.15.251.145   35.244.71.53   80:32363/TCP,443:30587/TCP   12d
service/ingress-nginx-ingress-controller-stats   ClusterIP      10.15.240.235   <none>         18080/TCP                    12d
service/ingress-nginx-ingress-default-backend    ClusterIP      10.15.243.113   <none>         80/TCP                       12d
service/prometheus-kube-state-metrics            ClusterIP      None            <none>         80/TCP                       12d
service/prometheus-prometheus-server             ClusterIP      10.15.254.80    <none>         80/TCP                       12d
service/tiller-deploy                            ClusterIP      10.15.253.242   <none>         44134/TCP                    12d
NAME                                                    DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/certmanager-cert-manager                1         1         1            1           12d
deployment.apps/ingress-nginx-ingress-controller        1         1         1            1           12d
deployment.apps/ingress-nginx-ingress-default-backend   1         1         1            1           12d
deployment.apps/prometheus-kube-state-metrics           1         1         1            1           12d
deployment.apps/prometheus-prometheus-server            1         1         1            1           12d
deployment.apps/runner-gitlab-runner                    1         1         1            1           12d
deployment.apps/tiller-deploy                           1         1         1            1           12d
NAME                                                               DESIRED   CURRENT   READY   AGE
replicaset.apps/certmanager-cert-manager-6c8cd9f9bf                1         1         1       12d
replicaset.apps/ingress-nginx-ingress-controller-ff666c548         1         1         1       12d
replicaset.apps/ingress-nginx-ingress-default-backend-6679dd498c   1         1         1       12d
replicaset.apps/prometheus-kube-state-metrics-8668948654           1         1         1       12d
replicaset.apps/prometheus-prometheus-server-746bb67956            1         1         1       12d
replicaset.apps/runner-gitlab-runner-9df899f44                     1         1         1       12d
replicaset.apps/tiller-deploy-9768f6964                            1         1         1       12d
#+END_EXAMPLE

** our project namespace

Our ~apisnoop-ci~ namespace contains our deployments based on
environment/branches.

#+NAME: apisnoop-ci namespace
#+BEGIN_SRC shell
  kubectl --namespace=apisnoop-ci get all 
#+END_SRC

#+RESULTS: apisnoop-ci namespace
#+BEGIN_EXAMPLE :noeval t
NAME                                            READY   STATUS    RESTARTS   AGE
pod/cm-acme-http-solver-fjq6p                   1/1     Running   0          7m
pod/cm-acme-http-solver-jxhnr                   1/1     Running   0          7m
pod/production-fb874dbcc-wmrvf                  1/1     Running   0          7m
pod/review-ci-app-env-nsqkug-965b67d74-2z5r9    1/1     Running   0          1h
pod/review-local-anim-ebqfjx-7457c97b5c-cmwff   1/1     Running   0          20h
pod/review-tix-121-ltf42v-6bdcc78c85-jwg8d      1/1     Running   0          20m
pod/staging-54445f7cd6-lk2c4                    1/1     Running   0          7m
NAME                                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
service/cm-acme-http-solver-28hw8              NodePort    10.15.246.2     <none>        8089:32658/TCP   7m
service/cm-acme-http-solver-rtbt7              NodePort    10.15.246.236   <none>        8089:30586/TCP   7m
service/review-ci-app-env-nsqkug-auto-deploy   ClusterIP   10.15.243.105   <none>        5000/TCP         16h
service/review-local-anim-ebqfjx-auto-deploy   ClusterIP   10.15.255.49    <none>        5000/TCP         20h
service/review-tix-121-ltf42v-auto-deploy      ClusterIP   10.15.245.117   <none>        5000/TCP         1d
NAME                                       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/production                 1         1         1            1           1d
deployment.apps/review-ci-app-env-nsqkug   1         1         1            1           16h
deployment.apps/review-local-anim-ebqfjx   1         1         1            1           20h
deployment.apps/review-tix-121-ltf42v      1         1         1            1           1d
deployment.apps/staging                    1         1         1            1           2d
NAME                                                  DESIRED   CURRENT   READY   AGE
replicaset.apps/production-fb874dbcc                  1         1         1       1d
replicaset.apps/review-ci-app-env-nsqkug-56dc5fbdd4   0         0         0       16h
replicaset.apps/review-ci-app-env-nsqkug-965b67d74    1         1         1       1h
replicaset.apps/review-local-anim-ebqfjx-7457c97b5c   1         1         1       20h
replicaset.apps/review-tix-121-ltf42v-567ccfb9dc      0         0         0       1d
replicaset.apps/review-tix-121-ltf42v-588c574d9f      0         0         0       1d
replicaset.apps/review-tix-121-ltf42v-58f7bf798       0         0         0       19h
replicaset.apps/review-tix-121-ltf42v-6bdcc78c85      1         1         1       20m
replicaset.apps/review-tix-121-ltf42v-7cfd94d94c      0         0         0       1d
replicaset.apps/review-tix-121-ltf42v-8f4c798c6       0         0         0       1d
replicaset.apps/staging-54445f7cd6                    1         1         1       1h
replicaset.apps/staging-56b4657fbd                    0         0         0       2d
replicaset.apps/staging-646978764f                    0         0         0       1h
replicaset.apps/staging-79bb68df49                    0         0         0       19h
replicaset.apps/staging-7d78c78465                    0         0         0       2d
replicaset.apps/staging-85df9ccbb9                    0         0         0       1d
replicaset.apps/staging-dccc64786                     0         0         0       1d
#+END_EXAMPLE

** project pods

#+NAME: apisnoop-ci pods
#+BEGIN_SRC shell
  kubectl --namespace=apisnoop-ci get pods 
#+END_SRC

#+RESULTS: apisnoop-ci pods
#+BEGIN_EXAMPLE :noeval t
NAME                                     READY   STATUS    RESTARTS   AGE
cm-acme-http-solver-f7cz7                1/1     Running   0          18h
cm-acme-http-solver-qb8lg                1/1     Running   0          16h
production-fb874dbcc-h5z7s               1/1     Running   0          18h
review-tix-121-ltf42v-7cfd94d94c-qcbmv   1/1     Running   0          15h
staging-dccc64786-bhhhj                  1/1     Running   0          16h
#+END_EXAMPLE
*** current review pod
#+NAME review pod
#+BEGIN_SRC shell
kubectl describe --namespace=apisnoop-ci pod/review-tix-121-ltf42v-7cfd94d94c-qcbmv
#+END_SRC

#+RESULTS:
#+BEGIN_EXAMPLE :noeval t
Name:               review-download-f-5nlwri-688f86cc9c-vk22s
Namespace:          apisnoop-ci
Priority:           0
PriorityClassName:  <none>
Node:               gke-apisnoop-ci-default-pool-3fb18c85-whd7/10.152.0.13
Start Time:         Tue, 26 Mar 2019 09:44:28 +1300
Labels:             app=review-download-f-5nlwri
                    pod-template-hash=2449427757
                    release=review-download-f-5nlwri
                    tier=web
                    track=stable
Annotations:        checksum/application-secrets: 
Status:             Pending
IP:                 
Controlled By:      ReplicaSet/review-download-f-5nlwri-688f86cc9c
Containers:
  auto-deploy-app:
    Container ID:   
    Image:          registry.ii.coop/apisnoop/ci/download-fix:50db9d03ac86e85a5f5dcf1d5a6a11a7ce65c16d
    Image ID:       
    Port:           5000/TCP
    Host Port:      0/TCP
    State:          Waiting
      Reason:       ContainerCreating
    Ready:          False
    Restart Count:  0
    Liveness:       http-get http://:5000/ delay=15s timeout=15s period=10s #success=1 #failure=3
    Readiness:      http-get http://:5000/ delay=5s timeout=3s period=10s #success=1 #failure=3
    Environment Variables from:
      review-download-f-5nlwri-secret  Secret  Optional: false
    Environment:
      DATABASE_URL:  postgres://user:testing-password@review-download-f-5nlwri-postgres:5432/review-download-f-5nlwri
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-xsmbr (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  default-token-xsmbr:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-xsmbr
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age    From                                                 Message
  ----    ------     ----   ----                                                 -------
  Normal  Scheduled  5m1s   default-scheduler                                    Successfully assigned apisnoop-ci/review-download-f-5nlwri-688f86cc9c-vk22s to gke-apisnoop-ci-default-pool-3fb18c85-whd7
  Normal  Pulling    4m57s  kubelet, gke-apisnoop-ci-default-pool-3fb18c85-whd7  pulling image "registry.ii.coop/apisnoop/ci/download-fix:50db9d03ac86e85a5f5dcf1d5a6a11a7ce65c16d"
#+END_EXAMPLE

* Digging into an environment / deployment

- Production, Staging, Review/Branch
[[https://gitlab.ii.coop/apisnoop/ci/environments]]
- Focus on Review/Branch
[[https://gitlab.ii.coop/apisnoop/ci/environments/folders/review]]
- Choose your environment, rollback to prior deployments if need be
[[https://gitlab.ii.coop/apisnoop/ci/environments/42]]
- If you been designated access, you can get a shell
[[https://gitlab.ii.coop/apisnoop/ci/environments/42/terminal]]

** gitlab environments => k8s deployments

#+NAME: apisnoop-ci deployments
#+BEGIN_SRC shell
  kubectl --namespace=apisnoop-ci get deployments
#+END_SRC

#+RESULTS: apisnoop-ci deployments
#+BEGIN_EXAMPLE :noeval t
NAME                    DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
production              1         1         1            1           15h
review-tix-121-ltf42v   1         1         1            1           15h
staging                 1         1         1            1           21h
#+END_EXAMPLE

** gitlab environment => pod
   
#+NAME: review pod
#+BEGIN_SRC shell
  kubectl --namespace=apisnoop-ci get pods -o=name | grep review
#+END_SRC

#+RESULTS: review pod
#+BEGIN_EXAMPLE :noeval t
pod/review-tix-121-ltf42v-7cfd94d94c-qcbmv
#+END_EXAMPLE

*** executing commands / listing data within pod

#+NAME: commands inside deploy container
#+BEGIN_SRC shell
  kubectl --namespace=apisnoop-ci exec \
      review-tix-121-ltf42v-7cfd94d94c-qcbmv \
      -- \
     find /app/data-gen/processed/ -name apisnoop.json
#+END_SRC

#+RESULTS: commands inside deploy container
#+BEGIN_EXAMPLE :noeval t
/app/data-gen/processed/ci-kubernetes-e2e-gce-cos-k8sstable2-default/2010/apisnoop.json
/app/data-gen/processed/ci-kubernetes-e2e-gce-cos-k8sstable1-default/5953/apisnoop.json
/app/data-gen/processed/ci-kubernetes-e2e-gci-gce/36092/apisnoop.json
/app/data-gen/processed/ci-kubernetes-e2e-gce-cos-k8sbeta-default/10141/apisnoop.json
/app/data-gen/processed/ci-kubernetes-e2e-gce-cos-k8sstable3-default/507/apisnoop.json
#+END_EXAMPLE

*** review pod details
#+NAME: apisnoop-ci review pod 
#+BEGIN_SRC shell :noweb yes
  kubectl --namespace=apisnoop-ci describe pod/review-tix-121-ltf42v-7cfd94d94c-qcbmv
#+END_SRC

#+RESULTS: apisnoop-ci review pod
#+BEGIN_EXAMPLE :noeval t
Name:               review-tix-121-ltf42v-7cfd94d94c-qcbmv
Namespace:          apisnoop-ci
Priority:           0
PriorityClassName:  <none>
Node:               gke-apisnoop-ci-default-pool-3fb18c85-whd7/10.152.0.13
Start Time:         Tue, 26 Mar 2019 16:27:03 +1300
Labels:             app=review-tix-121-ltf42v
                    pod-template-hash=3798508507
                    release=review-tix-121-ltf42v
                    tier=web
                    track=stable
Annotations:        checksum/application-secrets: 
Status:             Running
IP:                 10.12.0.63
Controlled By:      ReplicaSet/review-tix-121-ltf42v-7cfd94d94c
Containers:
  auto-deploy-app:
    Container ID:   docker://ed96e9bf14e98d0209eddf37441cc6247bbdb7fa8bb2f276a40a2dcf952c0526
    Image:          registry.ii.coop/apisnoop/ci/tix-121:eccfa3ce17d457754ee1d544910aeea22d2af600
    Image ID:       docker-pullable://registry.ii.coop/apisnoop/ci/tix-121@sha256:e5d9f126cbd605b8ddbdda0d302205fc8fdd1383c4c2c7af177960e1f3d77e1f
    Port:           5000/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Tue, 26 Mar 2019 16:31:55 +1300
    Ready:          True
    Restart Count:  0
    Liveness:       http-get http://:5000/ delay=15s timeout=15s period=10s #success=1 #failure=3
    Readiness:      http-get http://:5000/ delay=5s timeout=3s period=10s #success=1 #failure=3
    Environment Variables from:
      review-tix-121-ltf42v-secret  Secret  Optional: false
    Environment:
      DATABASE_URL:  postgres://user:testing-password@review-tix-121-ltf42v-postgres:5432/review-tix-121-ltf42v
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-xsmbr (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  default-token-xsmbr:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-xsmbr
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:          <none>
#+END_EXAMPLE

** kubectl exec shell

#+BEGIN_SRC tmate
  kubectl --namespace=apisnoop-ci exec -ti \
        review-tix-121-ltf42v-7cfd94d94c-qcbmv \
        /bin/bash
#+END_SRC

#+BEGIN_SRC tmate
cd /app/data-gen/processed
#+END_SRC

* Debugging a build

** retrieving the trace

These files look to be in the wrong location:

[[https://gitlab.ii.coop/apisnoop/ci/-/jobs/1908]]

The herokuish runs against a dind:

#+BEGIN_SRC shell
export DOCKER_HOST=tcp://localhost:2375
docker exec -ti ci_job_build_1802 /bin/bash
#+END_SRC

#+NAME: build trace
#+BEGIN_SRC shell
  . .env
  curl --header "PRIVATE-TOKEN: $GITLAB_PRIVATE_TOKEN" \
   "https://gitlab.ii.coop/api/v4/projects/apisnoop%2Fci/jobs/1919/trace"
#+END_SRC

#+RESULTS: build trace
#+BEGIN_EXAMPLE :noeval t
[0KRunning with gitlab-runner 11.6.0 (f100a208)
[0;m[0K  on runner-gitlab-runner-9df899f44-smgtx zF8zF8Jb
[0;m[0KUsing Kubernetes namespace: gitlab-managed-apps
[0;m[0KUsing Kubernetes executor with image alpine:latest ...
[0;msection_start:1553719639:prepare_script[0KWaiting for pod gitlab-managed-apps/runner-zf8zf8jb-project-142-concurrent-04lbqw to be running, status is Pending
Running on runner-zf8zf8jb-project-142-concurrent-04lbqw via runner-gitlab-runner-9df899f44-smgtx...
section_end:1553719642:prepare_script[0Ksection_start:1553719642:get_sources[0K[32;1mCloning repository...[0;m
Cloning into '/apisnoop/ci'...
#+END_EXAMPLE

For some reason it's showing we aren't logged into the namespace

[[https://gitlab.ii.coop/apisnoop/ci/-/jobs/1786]]

#+NAME: deploy failing on ensure_namespace
#+BEGIN_SRC shell
  . .env
  curl --header "PRIVATE-TOKEN: $GITLAB_PRIVATE_TOKEN" "https://gitlab.ii.coop/api/v4/projects/apisnoop%2Fci/jobs/1786/trace" \
  | grep -A2 ensure_namespace
#+END_SRC

#+RESULTS: deploy
#+BEGIN_EXAMPLE :noeval t
[32;1m$ ensure_namespace[0;m
error: You must be logged in to the server (Unauthorized)
error: You must be logged in to the server (Unauthorized)
#+END_EXAMPLE

** build container  
#+BEGIN_SRC shell
kubectl --namespace=gitlab-managed-apps get pods | grep 142 | awk '{print $1}'
#+END_SRC

#+RESULTS:
#+BEGIN_EXAMPLE :noeval t
runner-zf8zf8jb-project-142-concurrent-0rs9b8
#+END_EXAMPLE

#+BEGIN_SRC shell
  (
    kubectl --namespace=gitlab-managed-apps get pods
  ) 2>&1
  :
#+END_SRC

#+RESULTS:
#+BEGIN_EXAMPLE :noeval t
NAME                                                     READY   STATUS    RESTARTS   AGE
certmanager-cert-manager-6c8cd9f9bf-kjjsq                1/1     Running   3          12d
ingress-nginx-ingress-controller-ff666c548-vgcjr         1/1     Running   0          12d
ingress-nginx-ingress-default-backend-6679dd498c-nqh7p   1/1     Running   0          12d
install-certmanager                                      0/1     Error     0          2d
install-ingress                                          0/1     Error     0          2d
install-prometheus                                       0/1     Error     0          2d
install-runner                                           0/1     Error     0          2d
prometheus-kube-state-metrics-8668948654-6qj5m           1/1     Running   0          12d
prometheus-prometheus-server-746bb67956-dzxz9            2/2     Running   0          12d
runner-gitlab-runner-9df899f44-smgtx                     1/1     Running   0          12d
tiller-deploy-9768f6964-qtb9m                            1/1     Running   0          12d
#+END_EXAMPLE


#+BEGIN_SRC shell
  (
    kubectl --namespace=gitlab-managed-apps logs \
          runner-zf8zf8jb-project-142-concurrent-0rs9b8 \
            -c review
  ) 2>&1
  :
#+END_SRC

#+RESULTS:
#+BEGIN_EXAMPLE :noeval t
Error from server (NotFound): pods "runner-zf8zf8jb-project-142-concurrent-0rs9b8" not found
#+END_EXAMPLE

#+BEGIN_SRC tmate
  kubectl --namespace=gitlab-managed-apps exec -ti \
          runner-zf8zf8jb-project-142-concurrent-02pzqk \
          -c build /bin/sh
#+END_SRC

We need to choose a specific container:

#+BEGIN_EXAMPLE
Error from server (BadRequest):
a container name must be specified for pod runner-zf8zf8jb-project-142-concurrent-0csdmb,
 choose one of: [build helper svc-0]
#+END_EXAMPLE

** repository image
The build job log will contain the registry + tag the image was pushed to.

#+BEGIN_EXAMPLE
Configuring registry.ii.coop/apisnoop/ci/master:c2351d87cc36f0a1ef117c4caff3851312d514e6 docker image...
#+END_EXAMPLE

If you want to poke around the resulting image you can run the following:

#+BEGIN_SRC shell
docker pull registry.ii.coop/apisnoop/ci/master:c2351d87cc36f0a1ef117c4caff3851312d514e6
#+END_SRC

** prodction pod
#+BEGIN_SRC shell
kubectl logs production-fb874dbcc-h5z7s --namespace=apisnoop-ci
#+END_SRC

#+RESULTS:
#+BEGIN_EXAMPLE :noeval t

> backend@0.0.0 start /app
> node src/

info: Feathers application started on http://backend-app.feathersjs.com:5000
[ 'ci-kubernetes-e2e-gce-cos-k8sbeta-default',
  '9058',
  'apisnoop.json' ]
[ 'ci-kubernetes-e2e-gce-cos-k8sstable1-default',
  '5403',
  'apisnoop.json' ]
[ 'ci-kubernetes-e2e-gce-cos-k8sstable2-default',
  '1814',
  'apisnoop.json' ]
[ 'ci-kubernetes-e2e-gce-cos-k8sstable3-default',
  '460',
  'apisnoop.json' ]
[ 'ci-kubernetes-e2e-gci-gce', '34681', 'apisnoop.json' ]
[ 'ci-kubernetes-e2e-gce-cos-k8sbeta-default',
  '9058',
  'metadata.json' ]
[ 'ci-kubernetes-e2e-gce-cos-k8sstable1-default',
  '5403',
  'metadata.json' ]
[ 'ci-kubernetes-e2e-gce-cos-k8sstable2-default',
  '1814',
  'metadata.json' ]
[ 'ci-kubernetes-e2e-gce-cos-k8sstable3-default',
  '460',
  'metadata.json' ]
[ 'ci-kubernetes-e2e-gci-gce', '34681', 'metadata.json' ]
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/Tj7OR8y4WNGfCWNAVfV1er9cqZTdVvVadGUYZ313ifQ"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/DpBgs0io_Q_zrDrhLGtNCWeccJ_d05_88dpCKVpo3cM"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/aXMBUsXg9VLAqHENMVxaTAi62BFx6YhancOZzXWDZSk"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/YzH18rpP72WkPB7HJ69we1oZj5tQcrNBd8TTns8p9uQ"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/-MpKa4NxnCcTY3pb9ogt4UgW3LB6P90jWCiWHDp7xG0"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/mwB2vGdQRwG8aHy2wckoj0Dj6pT1-_gEGODzmmMVjsU"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/ExDmFLtuXwMmQokLlB_rO6QloF4RTyvkrCv2JDrJ8Ks"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/VTjS3l9gtOQTEX_MbeCC3OjB_-VwyLk__SXxiTM9WdI"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/S6fD1G2OSY_t0VRvQRQoAP6muNjlfDFG8d6ZQfrpBkk"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/9AH82jqoQy1BazTmenKcWtKtB7fcZrhCBNmx3HtR1pw"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/67ZAHi-segEa52IJ8HWqjr4Y3tuH3rkMHI4ItCRrqEg"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/Lc_jTKGtWtd3SBRF3b23MUPOAD1fHHitB4bzQIJAAXs"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/robots.txt"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/1ykOSu3FXffPt9wQ1jS311MCJM4tXJcFWpKRTyywr9U"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/Q8ZxsjPpM-9bfXX0e14G7X04YXZDyydSDEvUofCSI_g"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/uKVNbERd-OHYmnS0-VELhMtPp5mmHvsxa7uijyHTHMI"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/jyQyAjuvEmWhlOTk9B2y_9iNTD_kvUJ-SSW7j3Jr4MU"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/Q2al5afy_5Prf6sRlD6AnyLzwM_lT2r-lkPal09QE5E"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/1WIOcSm7WcUAx36reMXIwv0bQ5bQ5qiIPOROI8eFmBI"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/ftPBW51JtCE1SjzF3j0pQfdBYpsj8s_vQxmHyk1iCNM"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/MMSU27IafyKCJ0Oi6_LxJgQgnt0O57ZMGmZda1Smf6s"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/GMdwWQZlgUAvi9G2KuxJAUPjmjCNOKLLlwcGCF5jdVo"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/OH3dtr6L-Mp5Y7UB8MPRfToKF2003BNNnJugpvp3Lmc"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/W9QUlmluWM2z_g-1sCrexSCS4Jrg4vrw_K1Nx2LPoVk"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/nxPefrH_k0KDQXYpDWxupNk6MPKJ4TWgq5r5PllWmUY"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/SSYKfIxeyBOjm0yaq1G_EQLdhkyQQhACSuh4Wb8v-Q4"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/uV6rebzwAYUHnnX3ymx3GlgF-7F63xSvACePefVyPJc"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/9qpg3sHTZha8-LvnguQnfw_dvUepuz7jNfHIWF8oKGo"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/ph8IBEVpp0K9U-8GzZSG1h6uZyVp55k9FvgRnal38VE"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/v86QXDVZ58e-M1WU-RjSXKpzfxYcDtPBRH-kg0FkMU0"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/I4BiMInugfDVLizyP9b8ax3l5BJHw9VWdgN2hy8a8Ec"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/sunburst-apps/index.html"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/e8jhsqqnqj2xMO-0FNfXMmAakvxbpLNXXsmOji8-e5s"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/Q9O8cbIiNNFhez5vfHq85gKRO7CRgLv2N2txsGiq4C4"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/pYBQPajv3mCnzZOoVgNE4qMElV5cGxP1B_oVVYoYCRc"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/rVYDoZ3AnVPvVNindGzmKNu31qNXd9yRHte74ZElARo"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/ZJkbTs6n0O9l0tPDk7WuPWbx1TJ-Sv94GxlvWTVlg_o"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/C2IM0oNNpeClSWQg2Xagp6RRk0HlISOs4pfsTESe6Nw"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/J46dIC5PkUO-jvT2qTdar-iy86WJZd4bIc0v85NUXXA"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/robots.txt"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/pkSnJcMY_Q58wzUD1utrVxwWMxqjuNcpQFSL47Xe_6w"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/qdMn8TMvywV8tRy0ZCXvqLLYMnF4P2WgvRkg8eDLNdw"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/UlTbq12zHHzQ7YT-GN0n1A6SYBvkycp7kq6jH8rLhwI"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/OZMCpLWM0mO0GsnTEQBSPZg7X1eoYCrDoFXy7pyLPDQ"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/robots.txt"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/7zvRRLiIr-6c33_a2NbsKPGk4fdYFGC5QynZUQ9HQSA"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/ci-kubernetes-e2e-gci-gce_34681"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/c4wXHf7KDPfNQ1wGAT1JTdEccwcMxosg7NEaV_sN-NE"},"errors":{}}
error: Page not found {"type":"FeathersError","name":"NotFound","code":404,"className":"not-found","data":{"url":"/.well-known/acme-challenge/3jYDh9FJgfvzAJ3oukVEWMduQ6drT5Oyx1MY9syevbc"},"errors":{}}
#+END_EXAMPLE

* Babel

** Environments
https://docs.gitlab.com/ee/api/environments.html

#+NAME: get environment
#+BEGIN_SRC shell :var PROJECT="apisnoop%2Fci" ENVIRONMENT="production"
  . .env
  curl --header "PRIVATE-TOKEN: $GITLAB_PRIVATE_TOKEN" \
    https://gitlab.ii.coop/api/v4/projects/$PROJECT/environments \
  | jq -r -c "map(select(.name | contains(\"$ENVIRONMENT\"))) | .[] .id"
#+END_SRC

#+RESULTS: get environment
#+BEGIN_EXAMPLE :noeval t
41
#+END_EXAMPLE

#+NAME: get_environment_url
#+BEGIN_SRC shell :noweb yes :var PROJECT="apisnoop%2Fci" ENVIRONMENT="production"
echo <<get environment(PROJECT,ENVIRONMENT)>>
#+END_SRC

#+RESULTS: get foo environment
#+BEGIN_EXAMPLE :noeval t
42
45
46
47
48
49

#+END_EXAMPLE

* TIL
  Delete Environments
#+NAME: Delete Environment
#+BEGIN_SRC shell
  . .env
  curl --request DELETE --header "PRIVATE-TOKEN: $GITLAB_PRIVATE_TOKEN" \
    "https://gitlab.ii.coop/api/v4/projects/142/environments/40"
#+END_SRC

#+RESULTS: Delete Environment
#+BEGIN_EXAMPLE :noeval t
#+END_EXAMPLE

#+RESULTS:
#+BEGIN_EXAMPLE :noeval t
#+END_EXAMPLE
** retreving cluster creds

#+NAME: use admin creds locally
#+BEGIN_SRC shell :wrap "SRC yaml"
  kubectl config view --merge --minify --flatten \
  | grep -v access-token
#+END_SRC
#+RESULTS: use admin creds locally
#+BEGIN_SRC yaml
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURDekNDQWZPZ0F3SUJBZ0lRT0J3VEwvck15ZWNDczRyTFk5WTRRVEFOQmdrcWhraUc5dzBCQVFzRkFEQXYKTVMwd0t3WURWUVFERXlSbU9UUm1OelZoTnkxa04yWmtMVFJoTURrdE9UYzBZeTAyT0RGa01qVTBOR0pqTWpjdwpIaGNOTVRrd016RTFNVFl4TWpBMFdoY05NalF3TXpFek1UY3hNakEwV2pBdk1TMHdLd1lEVlFRREV5Um1PVFJtCk56VmhOeTFrTjJaa0xUUmhNRGt0T1RjMFl5MDJPREZrTWpVME5HSmpNamN3Z2dFaU1BMEdDU3FHU0liM0RRRUIKQVFVQUE0SUJEd0F3Z2dFS0FvSUJBUURBWnJIeUllbnBDUERZcmdmTjFYNFd0NmYvUTF1K2doUm5OTFdhaDBtaAp5L29YdDJtQmk4VWU2anpQeXJzdkRWd3FpSGVrMkoxTjJOT0hKWW1RQjdiRCs1ekVERWVaQnc5b2dBcWI3REtFClNVUCtsaE5FTGhTYUF0dHpRVzBEUjdPUlRlRmp0V0pJejNZZmg4dVlMMy9kTWFCa0xMNHlNMjhPb0YyRjN2YzcKL1dLUmdsNDUvd2VleUwvc0NjVmQwYW50R1BlUDZJNXRyRC9kRVZpRUo2UWkzYzlIU01CTkE0MFFBcTRuSFpZZAozV01QWkhoRmNKZ2hTTjZxZmVkMUdzc25XdmFMWGNBL2VlVUowVVI0ZnFkTUJVQU5zd0VTS1lLQTg4M1ZNczdJCjUrZHljdHFPbUcvd29LUUJzcFpDcHI3RXJybDlTcktOUHJXNDlTRXF4eU9oQWdNQkFBR2pJekFoTUE0R0ExVWQKRHdFQi93UUVBd0lDQkRBUEJnTlZIUk1CQWY4RUJUQURBUUgvTUEwR0NTcUdTSWIzRFFFQkN3VUFBNElCQVFCdgoybzZqQ285TDcyZFllSUFCS1JsQlAxQU9VdzcrOXFtYjV0Y0JyTU11aW5pOEc1Y1lzaDRzUXNGZnZERVNMaldnCmFBSU1uVHEySm4yUnZOUTVJdkhZNllVU3k3MXh3bndBUnhGN2wyVHptVUZ3NFhlVG0xWTMzakFobmhnNE5GNWgKblRoek4wc2dSbVJrRzkwL1BuTUdTYkpYTzFob0pTL1ViWTVsbkU2ak93WFlWNnVTREM4cE41dHZ4MTlSWS9JVQo5TlBKRUp5a2I4VWF3WWIzS2pzV1JVdXBJTVprKzNIZ1lrT3lsbzE5SU9IRzdyTTNQV2pMbngrSTdGRlk3OXM1CnA1K3RUWUhhbDdyVEpIQTN1dFdzODJRc1J0RE9XbFczN0JKcEk5VWRCb1U3UmJYR3Z0VjcrV1NEM0dnbTNrZ20Kd2NiTEx2eUhWbnMycjRiWU9mbmoKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    server: https://35.201.3.241
  name: gke_apisnoop_australia-southeast1-c_apisnoop-ci
contexts:
- context:
    cluster: gke_apisnoop_australia-southeast1-c_apisnoop-ci
    user: gke_apisnoop_australia-southeast1-c_apisnoop-ci
  name: gke_apisnoop_australia-southeast1-c_apisnoop-ci
current-context: gke_apisnoop_australia-southeast1-c_apisnoop-ci
kind: Config
preferences: {}
users:
- name: gke_apisnoop_australia-southeast1-c_apisnoop-ci
  user:
    auth-provider:
      config:
        cmd-args: config config-helper --format=json
        cmd-path: /usr/lib/google-cloud-sdk/bin/gcloud
        expiry: "2019-03-26T16:41:26Z"
        expiry-key: '{.credential.token_expiry}'
        token-key: '{.credential.access_token}'
      name: gcp
#+END_SRC

** retreiving a job trace 
https://docs.gitlab.com/ee/api/jobs.html#get-a-trace-file
https://docs.gitlab.com/ee/api/README.html#namespaced-path-encoding
#+NAME: job trace example
#+BEGIN_SRC shell :results silent
  . .env
  curl --header "PRIVATE-TOKEN: $GITLAB_PRIVATE_TOKEN" "https://gitlab.ii.coop/api/v4/projects/apisnoop%2Fci/jobs/1786/trace"
#+END_SRC

** retrieving a job ENV
We inspect the environment of pid 1 and use grep to sort it nicely

#+BEGIN_SRC shell
kubectl --namespace=gitlab-managed-apps exec -ti \
 runner-zf8zf8jb-project-142-concurrent-0dl4pg \
 -c build -- /bin/sh -c \
 'cat /proc/1/environ | grep =' | sort
#+END_SRC

#+RESULTS:
#+BEGIN_EXAMPLE :noeval t
AUTO_DEVOPS_DOMAIN=apisnoop.cncf.ci
CI_API_V4_URL=https://gitlab.ii.coop/api/v4
CI_BUILD_BEFORE_SHA=ef143bd7e1583068b78cb2cf8d3be16d270e1cb4
CI_BUILD_ID=1795
CI_BUILD_NAME=review
CI_BUILD_REF=1caf563c3cba6336036f867ae2d85fa4ee345718
CI_BUILD_REF_NAME=gitlab-ci.yaml
CI_BUILD_REF_SLUG=gitlab-ci-yaml
CI_BUILD_STAGE=review
CI_COMMIT_BEFORE_SHA=ef143bd7e1583068b78cb2cf8d3be16d270e1cb4
CI_COMMIT_DESCRIPTION=
CI_COMMIT_MESSAGE=Debugging .gitlab-ci.yml
CI_COMMIT_REF_NAME=gitlab-ci.yaml
CI_COMMIT_REF_SLUG=gitlab-ci-yaml
CI_COMMIT_SHA=1caf563c3cba6336036f867ae2d85fa4ee345718
CI_COMMIT_SHORT_SHA=1caf563c
CI_COMMIT_TITLE=Debugging .gitlab-ci.yml
CI_CONFIG_PATH=.gitlab-ci.yml
CI_DISPOSABLE_ENVIRONMENT=true
CI_ENVIRONMENT_NAME=review/gitlab-ci.yaml
CI_ENVIRONMENT_SLUG=review-gitlab-ci-3s76v0
CI_ENVIRONMENT_URL=http://apisnoop-ci-review-gitlab-ci-3s76v0.apisnoop.cncf.ci
CI_JOB_ID=1795
CI_JOB_NAME=review
CI_JOB_STAGE=review
CI_JOB_URL=https://gitlab.ii.coop/apisnoop/ci/-/jobs/1795
CI_NODE_TOTAL=1
CI_PIPELINE_ID=262
CI_PIPELINE_IID=48
CI_PIPELINE_SOURCE=push
CI_PIPELINE_URL=https://gitlab.ii.coop/apisnoop/ci/pipelines/262
CI_PROJECT_DIR=/apisnoop/ci
CI_PROJECT_ID=142
CI_PROJECT_NAME=ci
CI_PROJECT_NAMESPACE=apisnoop
CI_PROJECT_PATH=apisnoop/ci
CI_PROJECT_PATH_SLUG=apisnoop-ci
CI_PROJECT_URL=https://gitlab.ii.coop/apisnoop/ci
CI_PROJECT_VISIBILITY=public
CI_REGISTRY_IMAGE=registry.ii.coop/apisnoop/ci
CI_REGISTRY=registry.ii.coop
CI_REGISTRY_USER=gitlab-ci-token
CI_RUNNER_DESCRIPTION=
CI_RUNNER_EXECUTABLE_ARCH=linux/amd64
CI_RUNNER_ID=6
CI_RUNNER_REVISION=f100a208
CI_RUNNER_TAGS=cluster, kubernetes
CI_RUNNER_VERSION=11.6.0
CI_SERVER_NAME=GitLab
CI_SERVER_REVISION=ed04633
CI_SERVER_TLS_CA_FILE=-----BEGIN CERTIFICATE-----
CI_SERVER_VERSION=11.7.5-ee
CI_SERVER_VERSION_MAJOR=11
CI_SERVER_VERSION_MINOR=7
CI_SERVER_VERSION_PATCH=5
CI_SERVER=yes
CI=true
DOCKER_DRIVER=overlay2
FF_K8S_USE_ENTRYPOINT_OVER_COMMAND=true
GITLAB_CI=true
GITLAB_FEATURES=audit_events,burndown_charts,code_owners,contribution_analytics,elastic_search,export_issues,group_burndown_charts,group_webhooks,issuable_default_templates,issue_board_focus_mode,issue_weights,jenkins_integration,ldap_group_sync,member_lock,merge_request_approvers,multiple_ldap_servers,multiple_issue_assignees,multiple_project_issue_boards,push_rules,project_creation_level,protected_refs_for_users,related_issues,repository_mirrors,repository_size_limit,scoped_issue_board,admin_audit_log,auditor_user,board_assignee_lists,board_milestone_lists,cross_project_pipelines,custom_file_templates,custom_file_templates_for_namespace,email_additional_text,db_load_balancing,deploy_board,extended_audit_events,file_locks,geo,github_project_service_integration,jira_dev_panel_integration,ldap_group_sync_filter,multiple_clusters,multiple_group_issue_boards,merge_request_performance_metrics,object_storage,group_saml,service_desk,smartcard_auth,unprotection_restrictions,variable_environment_scope,reject_unsigned_commits,commit_committer_check,external_authorization_service,ci_cd_projects,protected_environments,system_header_footer,custom_project_templates,packages,code_owner_as_approver_suggestion,feature_flags,batch_comments,issues_analytics,security_dashboard,dependency_scanning,license_management,sast,sast_container,container_scanning,cluster_health,dast,epics,chatops,pod_logs,pseudonymizer,prometheus_alerts,operations_dashboard,tracing,web_ide_terminal
GITLAB_USER_EMAIL=hh@ii.coop
GITLAB_USER_ID=2
GITLAB_USER_LOGIN=hh
GITLAB_USER_NAME=Hippie Hacker
HELM_VERSION=2.11.0
HOME=/root
HOSTNAME=runner-zf8zf8jb-project-142-concurrent-0dl4pg
INCREMENTAL_ROLLOUT_ENABLED=1
INCREMENTAL_ROLLOUT_MODE=manual
INGRESS_NGINX_INGRESS_CONTROLLER_PORT_443_TCP_ADDR=10.15.251.145
INGRESS_NGINX_INGRESS_CONTROLLER_PORT_443_TCP_PORT=443
INGRESS_NGINX_INGRESS_CONTROLLER_PORT_443_TCP_PROTO=tcp
INGRESS_NGINX_INGRESS_CONTROLLER_PORT_443_TCP=tcp://10.15.251.145:443
INGRESS_NGINX_INGRESS_CONTROLLER_PORT_80_TCP_ADDR=10.15.251.145
INGRESS_NGINX_INGRESS_CONTROLLER_PORT_80_TCP_PORT=80
INGRESS_NGINX_INGRESS_CONTROLLER_PORT_80_TCP_PROTO=tcp
INGRESS_NGINX_INGRESS_CONTROLLER_PORT_80_TCP=tcp://10.15.251.145:80
INGRESS_NGINX_INGRESS_CONTROLLER_PORT=tcp://10.15.251.145:80
INGRESS_NGINX_INGRESS_CONTROLLER_SERVICE_HOST=10.15.251.145
INGRESS_NGINX_INGRESS_CONTROLLER_SERVICE_PORT=80
INGRESS_NGINX_INGRESS_CONTROLLER_SERVICE_PORT_HTTP=80
INGRESS_NGINX_INGRESS_CONTROLLER_SERVICE_PORT_HTTPS=443
INGRESS_NGINX_INGRESS_CONTROLLER_STATS_PORT_18080_TCP_ADDR=10.15.240.235
INGRESS_NGINX_INGRESS_CONTROLLER_STATS_PORT_18080_TCP_PORT=18080
INGRESS_NGINX_INGRESS_CONTROLLER_STATS_PORT_18080_TCP_PROTO=tcp
INGRESS_NGINX_INGRESS_CONTROLLER_STATS_PORT_18080_TCP=tcp://10.15.240.235:18080
INGRESS_NGINX_INGRESS_CONTROLLER_STATS_PORT=tcp://10.15.240.235:18080
INGRESS_NGINX_INGRESS_CONTROLLER_STATS_SERVICE_HOST=10.15.240.235
INGRESS_NGINX_INGRESS_CONTROLLER_STATS_SERVICE_PORT=18080
INGRESS_NGINX_INGRESS_CONTROLLER_STATS_SERVICE_PORT_STATS=18080
INGRESS_NGINX_INGRESS_DEFAULT_BACKEND_PORT_80_TCP_ADDR=10.15.243.113
INGRESS_NGINX_INGRESS_DEFAULT_BACKEND_PORT_80_TCP_PORT=80
INGRESS_NGINX_INGRESS_DEFAULT_BACKEND_PORT_80_TCP_PROTO=tcp
INGRESS_NGINX_INGRESS_DEFAULT_BACKEND_PORT_80_TCP=tcp://10.15.243.113:80
INGRESS_NGINX_INGRESS_DEFAULT_BACKEND_PORT=tcp://10.15.243.113:80
INGRESS_NGINX_INGRESS_DEFAULT_BACKEND_SERVICE_HOST=10.15.243.113
INGRESS_NGINX_INGRESS_DEFAULT_BACKEND_SERVICE_PORT=80
INGRESS_NGINX_INGRESS_DEFAULT_BACKEND_SERVICE_PORT_HTTP=80
KOqkqm57TH2H3eDJAkSnh6/DNFu0Qg==
KUBE_CA_PEM=-----BEGIN CERTIFICATE-----
KUBE_CA_PEM_FILE=-----BEGIN CERTIFICATE-----
KUBE_NAMESPACE=ci-142
KUBERNETES_PORT_443_TCP_ADDR=10.15.240.1
KUBERNETES_PORT_443_TCP_PORT=443
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_PORT_443_TCP=tcp://10.15.240.1:443
KUBERNETES_PORT=tcp://10.15.240.1:443
KUBERNETES_SERVICE_HOST=10.15.240.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_VERSION=1.10.9
KUBE_SERVICE_ACCOUNT=ci-142-service-account
KUBE_URL=https://35.201.3.241
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
POSTGRES_DB=review-gitlab-ci-3s76v0
POSTGRES_ENABLED=true
POSTGRES_PASSWORD=testing-password
POSTGRES_USER=user
PROMETHEUS_PROMETHEUS_SERVER_PORT_80_TCP_ADDR=10.15.254.80
PROMETHEUS_PROMETHEUS_SERVER_PORT_80_TCP_PORT=80
PROMETHEUS_PROMETHEUS_SERVER_PORT_80_TCP_PROTO=tcp
PROMETHEUS_PROMETHEUS_SERVER_PORT_80_TCP=tcp://10.15.254.80:80
PROMETHEUS_PROMETHEUS_SERVER_PORT=tcp://10.15.254.80:80
PROMETHEUS_PROMETHEUS_SERVER_SERVICE_HOST=10.15.254.80
PROMETHEUS_PROMETHEUS_SERVER_SERVICE_PORT=80
PROMETHEUS_PROMETHEUS_SERVER_SERVICE_PORT_HTTP=80
PWD=/
SHLVL=1
STAGING_ENABLED=1
TILLER_DEPLOY_PORT_44134_TCP_ADDR=10.15.253.242
TILLER_DEPLOY_PORT_44134_TCP_PORT=44134
TILLER_DEPLOY_PORT_44134_TCP_PROTO=tcp
TILLER_DEPLOY_PORT_44134_TCP=tcp://10.15.253.242:44134
TILLER_DEPLOY_PORT=tcp://10.15.253.242:44134
TILLER_DEPLOY_SERVICE_HOST=10.15.253.242
TILLER_DEPLOY_SERVICE_PORT=44134
TILLER_DEPLOY_SERVICE_PORT_TILLER=44134
#+END_EXAMPLE

** run kubectl commands within deploy job

I deleted the namespace, and apparently that was bad.

We wrap it in () and redirect stderr '2>&1' followed by : to ensure output
staging-7d78c78465-w628j 
#+NAME: attemp to run a kubectl command
#+BEGIN_SRC shell
  (
      kubectl --namespace=gitlab-managed-apps exec \
          runner-zf8zf8jb-project-142-concurrent-0dl4pg \
          -c build -- \
          kubectl get namespaces
  ) 2>&1
  :
#+END_SRC

#+RESULTS: failed attempt to run a kubectl command
#+BEGIN_EXAMPLE :noeval t
Error from server (Forbidden): namespaces is forbidden: User "system:serviceaccount:gitlab-managed-apps:default" cannot list namespaces at the cluster scope
command terminated with exit code 1
#+END_EXAMPLE
* [0/1] Future Features
- [ ] gitlab should provide the kubectl exec command to get a shell on a pod / container combo for a deploy
- [ ] gitlab should provide links to line numbers in job output
* Footnotes

# Local Variables:
# eval: (set (make-local-variable 'org-file-dir) (file-name-directory buffer-file-name))
# eval: (set (make-local-variable 'user-buffer) (concat user-login-name "." (file-name-base buffer-file-name)))
# eval: (set (make-local-variable 'tmpdir) (make-temp-file (concat "/dev/shm/" user-buffer "-") t))
# eval: (set (make-local-variable 'socket) (concat "/tmp/" user-buffer ".iisocket"))
# eval: (set (make-local-variable 'select-enable-clipboard) t)
# eval: (set (make-local-variable 'select-enable-primary) t)
# eval: (set (make-local-variable 'start-tmate-command) (concat "tmate -S " socket " new-session -A -s " user-login-name " -n main \"tmate wait tmate-ready && tmate display -p '#{tmate_ssh}' | xclip -i -sel p -f | xclip -i -sel c; bash --login\""))
# eval: (xclip-mode 1) 
# eval: (gui-select-text start-tmate-command)
# eval: (xclip-mode 1) 
# org-babel-tmate-session-prefix: ""
# org-babel-tmate-default-window-name: "main"
# org-use-property-inheritance: t
# End:
