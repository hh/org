#+TITLE: Which Cloud Ip Lookup
Investigation of https://pypi.org/project/which-cloud/#files
Based on https://github.com/SoundOn/which-cloud
* Get the repo
#+BEGIN_SRC shell
git clone https://github.com/SoundOn/which-cloud.git
#+END_SRC

* Look at json repo points to:
For the big 3 the repo points to 3 locations for json:
GCP-document: https://cloud.google.com/compute/docs/faq#find_ip_range
GCP-data: https://www.gstatic.com/ipranges/cloud.json
AWS-document: https://docs.aws.amazon.com/general/latest/gr/aws-ip-ranges.html
AWS-data: https://ip-ranges.amazonaws.com/ip-ranges.json
Azure-document: https://www.microsoft.com/en-us/download/details.aspx?id=56519
Azure-data: https://download.microsoft.com/download/7/1/D/71D86715-5596-4529-9B13-DA13A5DE5B63/ServiceTags_Public_20201109.json
** Look at GCP json
###+BEGIN_SRC tmate :window SHELL

#+BEGIN_SRC shell
curl 'https://www.gstatic.com/ipranges/cloud.json' | jq '.' | head
#+END_SRC

#+RESULTS:
#+begin_example
{
  "syncToken": "1622048579440",
  "creationTime": "2021-05-26T10:02:59.44",
  "prefixes": [
    {
      "ipv4Prefix": "34.80.0.0/15",
      "service": "Google Cloud",
      "scope": "asia-east1"
    },
    {
#+end_example

** Look at AWS json
###+BEGIN_SRC tmate :window SHELL

#+BEGIN_SRC shell
curl 'https://ip-ranges.amazonaws.com/ip-ranges.json' | jq '.' | head
#+END_SRC

#+RESULTS:
#+begin_example
{
  "syncToken": "1622066052",
  "createDate": "2021-05-26-21-54-12",
  "prefixes": [
    {
      "ip_prefix": "3.5.140.0/22",
      "region": "ap-northeast-2",
      "service": "AMAZON",
      "network_border_group": "ap-northeast-2"
    },
#+end_example

** Look at AWS json
###+BEGIN_SRC tmate :window SHELL
###+BEGIN_SRC shell
Note this url seems to change by date, make sure any automation accounts for it
#+BEGIN_SRC shell
curl 'https://download.microsoft.com/download/7/1/D/71D86715-5596-4529-9B13-DA13A5DE5B63/ServiceTags_Public_20210524.json' | jq '.' | head
#+END_SRC

#+RESULTS:
#+begin_example
{
  "changeNumber": 149,
  "cloud": "Public",
  "values": [
    {
      "name": "ActionGroup",
      "id": "ActionGroup",
      "properties": {
        "changeNumber": 9,
        "region": "",
#+end_example

* Push to bq
Login
#+BEGIN_SRC tmate gcloud-auth
gcloud auth login
#+END_SRC
Set project
#+BEGIN_SRC tmate gcloud-auth
gcloud config set project k8s-infra-ii-sandbox
#+END_SRC
Confirm
#+begin_src shell
gcloud config list --format 'value(core.project)' 2>/dev/null
#+end_src
#+RESULTS:
#+begin_example
k8s-infra-ii-sandbox
#+end_example

** Get google cloud.json local and load it into bq --FAILED
Simple local download for now
#+BEGIN_SRC shell
wget https://www.gstatic.com/ipranges/cloud.json
#+END_SRC
#+BEGIN_SRC shell
ls -al | grep cloud.json
#+END_SRC
Confirm
#+RESULTS:
#+begin_example
-rw-r--r--  1 ii ii  43248 May 27 05:08 cloud.json
#+end_example
Load into bq
mmmm it is getting errors... before I troubleshoot, let me try the same with aws
#+begin_src tmate :window bq-load
bq load --autodetect k8s_artifacts_dataset_bb_test.gcloud_ipranges_json ./cloud.json
#+end_src
#+BEGIN_SRC shell
wget https://ip-ranges.amazonaws.com/ip-ranges.json
#+END_SRC

#+BEGIN_SRC shell
ls -al | grep ip-ranges
#+END_SRC
#+RESULTS:
#+begin_example
-rw-r--r--  1 ii ii 846881 May 27 10:58 ip-ranges.json
#+end_example
#+begin_src tmate :window bq-load
bq load --autodetect k8s_artifacts_dataset_bb_test.amazon_ipranges_json ./ip-ranges.json
#+end_src
** Load the data in postgres for pre-processing
Bring up Postgres
#+BEGIN_SRC tmate :window postgres
docker run -it --rm -p 5432:5432 -e POSTGRES_PASSWORD=password -e POSTGRES_DB=ii postgres:12.2-alpine
#+END_SRC
#+BEGIN_SRC tmate :window pg-load :dir (concat (getenv "HOME") "")
mkdir json_dumps && cd json_dumps
#+END_SRC
#+BEGIN_SRC tmate :window pg-load :dir (concat (getenv "HOME") "/json_dumps")
wget 'https://download.microsoft.com/download/7/1/D/71D86715-5596-4529-9B13-DA13A5DE5B63/ServiceTags_Public_20210524.json' &&
wget 'https://ip-ranges.amazonaws.com/ip-ranges.json' &&
wget 'https://www.gstatic.com/ipranges/cloud.json'
#+END_SRC

Confirm we can connect:
#+BEGIN_SRC sql-mode
\dn
--SELECT schemaname, tablename FROM pg_catalog.pg_tables WHERE schemaname != 'pg_catalog' AND schemaname != 'information_schema';
#+END_SRC

Lets load some data into postgres
Lets put down a sql file that will let us load the data
#+BEGIN_SRC sql :tangle (concat (getenv "HOME") "/json_dumps/dump_loads.sql")
-- create table jsonraw(data jsonb);
\copy jsonraw(data) from '/home/ii/json_dumps/cloud.json' csv quote e'\x01' delimiter e'\x02';
#+END_SRC
Lets see what we get
#+BEGIN_SRC tmate :window pg-load :dir (concat (getenv "HOME") "/json_dumps")
psql -U postgres -d ii -h $SHARINGIO_PAIR_LOAD_BALANCER_IP < dump_loads.sql
#+END_SRC
Nope, here is a direct run to document the error.
#+BEGIN_SRC sql-mode
    \copy jsonraw(data) from '/home/ii/json_dumps/cloud.json' csv quote e'\x01' delimiter e'\x02';
#+END_SRC


Next I need to figure out what is wrong with my json,
Below I did a quick poke around with jq and I can navigate elements
That means the json is valid?

Guessing it is some convention, will poke around more later

#+BEGIN_SRC shell
cat /home/ii/json_dumps/cloud.json | jq '.prefixes[0].scope' | head
#+END_SRC

#+RESULTS:
#+begin_example
"asia-east1"
#+end_example

** Decision, I am going to output jsut the addresses and upload those to pg, done futsing with pg/bq parsing
Lets go make sure we can get to just ips
#+BEGIN_SRC tmate :window pg-load :dir (concat (getenv "HOME") "/json_dumps")
curl https://ip-ranges.amazonaws.com/ip-ranges.json | jq '.prefixes[].ip_prefix' > amazon_ipranges_only.txt
#+END_SRC
*** Turns out it is not needed to convert it to csv, still interesting:
Making it into a csv
From https://stackoverflow.com/questions/1251999/sed-how-can-i-replace-a-newline-n :
- Create a label via :a
- Append the current and next line to the pattern space via N
- If we are before the last line, branch to the created label $!ba ($! means not to do it on the last line (as there should be one final newline)).
- Finally the substitution replaces every newline with a comma on the pattern space (which is the whole file).
#+BEGIN_SRC tmate :window pg-load :dir (concat (getenv "HOME") "/json_dumps")
sed -i ':a;N;$!ba;s/\n/,/g' amazon_ipranges_only.txt
#+END_SRC
Remove all quotes
#+BEGIN_SRC tmate :window pg-load :dir (concat (getenv "HOME") "/json_dumps")
sed -i 's/"//g' amazon_ipranges_only.txt
#+END_SRC
*** Load amazon data to single table
#+BEGIN_SRC sql-mode
create table amazon_ips_only  (ip cidr);
\COPY amazon_ips_only from '/home/ii/json_dumps/amazon_ipranges_only.txt' DELIMITER ',' CSV;
#+END_SRC
Confirmation:
#+BEGIN_SRC sql-mode
select * from amazon_ips_only limit 10;
#+END_SRC

#+RESULTS:
#+begin_SRC example
        ip
------------------
 3.5.140.0/22
 13.34.37.64/27
 15.230.56.104/31
 35.180.0.0/16
 52.93.153.170/32
 52.93.178.234/32
 52.94.76.0/22
 52.95.36.0/22
 52.219.170.0/23
 99.87.32.0/22
(10 rows)

#+end_SRC

Split that into start and end
#+BEGIN_SRC sql-mode
select ip as ip,
host(network(ip)::inet) as ip_start,
host(broadcast(ip)::inet) as ip_end
into table expanded_ip3
from amazon_ips_only;
#+END_SRC

#+RESULTS:
#+begin_SRC example
SELECT 4541
#+end_SRC

#+BEGIN_SRC sql-mode
select * from expanded_ip3 limit 10;
#+END_SRC

#+RESULTS:
#+begin_SRC example
        ip        |   ip_start    |     ip_end
------------------+---------------+----------------
 3.5.140.0/22     | 3.5.140.0     | 3.5.143.255
 13.34.37.64/27   | 13.34.37.64   | 13.34.37.95
 15.230.56.104/31 | 15.230.56.104 | 15.230.56.105
 35.180.0.0/16    | 35.180.0.0    | 35.180.255.255
 52.93.153.170/32 | 52.93.153.170 | 52.93.153.170
 52.93.178.234/32 | 52.93.178.234 | 52.93.178.234
 52.94.76.0/22    | 52.94.76.0    | 52.94.79.255
 52.95.36.0/22    | 52.95.36.0    | 52.95.39.255
 52.219.170.0/23  | 52.219.170.0  | 52.219.171.255
 99.87.32.0/22    | 99.87.32.0    | 99.87.35.255
(10 rows)

#+end_SRC

#+begin_src sql-mode
\copy (select * from expanded_ip3) to '~/amazon_expanded_ipv4.csv' csv header;
#+end_src

#+RESULTS:
#+begin_SRC example
COPY 4541
#+end_SRC

#+begin_src shell
bq load --autodetect k8s_artifacts_dataset_bb_test.amazon_initial_expanded_ipv4 /home/ii/amazon_expanded_ipv4.csv
#+end_src

#+BEGIN_SRC shell
bq query --nouse_legacy_sql \
'
select * from k8s-infra-ii-sandbox.k8s_artifacts_dataset_bb_test.amazon_initial_expanded_ipv4 limit 10;
'
#+END_SRC

#+RESULTS:
#+begin_example
+----------------+----------------+----------------+
| string_field_0 | string_field_1 | string_field_2 |
+----------------+----------------+----------------+
| ip             | ip_start       | ip_end         |
| 3.0.5.32/29    | 3.0.5.32       | 3.0.5.39       |
| 3.4.2.0/27     | 3.4.2.0        | 3.4.2.31       |
| 3.4.2.0/27     | 3.4.2.0        | 3.4.2.31       |
| 3.2.0.0/24     | 3.2.0.0        | 3.2.0.255      |
| 3.2.0.0/24     | 3.2.0.0        | 3.2.0.255      |
| 3.2.2.0/24     | 3.2.2.0        | 3.2.2.255      |
| 3.2.2.0/24     | 3.2.2.0        | 3.2.2.255      |
| 3.2.3.0/24     | 3.2.3.0        | 3.2.3.255      |
| 3.2.3.0/24     | 3.2.3.0        | 3.2.3.255      |
+----------------+----------------+----------------+
#+end_example

#+BEGIN_SRC shell
bq query --nouse_legacy_sql \
'
SELECT
  "amazon" as name,
  string_field_0 as cidr_ip,
  string_field_1 as start_ip,
  string_field_2 end_ip,
  NET.IPV4_TO_INT64(NET.IP_FROM_STRING(string_field_1)) AS start_ip_int,
  NET.IPV4_TO_INT64(NET.IP_FROM_STRING(string_field_2)) AS end_ip
  from k8s-infra-ii-sandbox.k8s_artifacts_dataset_bb_test.amazon_initial_expanded_ipv4
  WHERE regexp_contains(string_field_1, r"^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}") limit 10;
'
#+END_SRC

#+RESULTS:
#+begin_example
#+end_example

#+BEGIN_SRC tmate :window pg-load :dir (concat (getenv "HOME") "/json_dumps")
#+END_SRC

#+BEGIN_SRC tmate :window pg-load :dir (concat (getenv "HOME") "/json_dumps")
#+END_SRC

  NET.IPV4_TO_INT64(NET.IP_FROM_STRING(end_ip)) AS end_ip
FROM   k8s-infra-ii-sandbox.k8s_artifacts_gcslogs_appspot.peeringdb_expanded_ipv4_20210524
